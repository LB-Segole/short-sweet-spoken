
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts'
import { createClient } from 'https://esm.sh/@supabase/supabase-js@2'
import { generateConversationResponse } from '../../../src/services/conversationService.ts'

console.log('üöÄ DeepGram Voice WebSocket initialized v2.0');

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
  'Access-Control-Allow-Methods': 'GET, POST, OPTIONS, UPGRADE',
}

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response(null, { headers: corsHeaders })
  }

  const url = new URL(req.url)
  const callId = url.searchParams.get('callId') || 'browser-test'
  const assistantId = url.searchParams.get('assistantId') || 'demo'
  const userId = url.searchParams.get('userId')

  const upgradeHeader = req.headers.get('upgrade')
  if (upgradeHeader?.toLowerCase() !== 'websocket') {
    return new Response('Expected websocket connection', {
      status: 426,
      headers: { ...corsHeaders, Upgrade: 'websocket', Connection: 'Upgrade' },
    })
  }

  const deepgramApiKey = Deno.env.get('Deepgram_API')
  if (!deepgramApiKey) {
    return new Response('DeepGram API key not configured', { status: 500, headers: corsHeaders })
  }

  try {
    const { socket, response } = Deno.upgradeWebSocket(req)
    
    const supabaseClient = createClient(
      Deno.env.get('SUPABASE_URL')!,
      Deno.env.get('SUPABASE_SERVICE_ROLE_KEY')!
    )

    let assistant: any = null
    let isCallActive = false
    let deepgramSTT: WebSocket | null = null
    let deepgramTTS: WebSocket | null = null
    let signalWireStreamSid: string | null = null
    let conversationBuffer: Array<{ role: string; content: string }> = []

    const log = (msg: string, data?: any) => 
      console.log(`[${new Date().toISOString()}] [Call: ${callId}] ${msg}`, data || '')

    // Load assistant configuration
    if (assistantId !== 'demo' && userId) {
      try {
        const { data: assistantData } = await supabaseClient
          .from('assistants')
          .select('*')
          .eq('id', assistantId)
          .eq('user_id', userId)
          .single()
        if (assistantData) {
          assistant = assistantData
          log('‚úÖ Assistant loaded', { name: assistant.name, personality: assistant.system_prompt })
        }
      } catch (err) {
        log('‚ö†Ô∏è Error fetching assistant, using default', err)
      }
    }

    if (!assistant) {
      assistant = {
        name: 'DeepGram Assistant',
        first_message: 'Hello! This is your AI assistant powered by DeepGram. How can I help you today?',
        system_prompt: 'You are a helpful AI assistant. Be friendly, professional, and concise.'
      }
    }

    // Initialize DeepGram STT with proper error handling
    const initializeSTT = () => {
      try {
        const sttUrl = 'wss://api.deepgram.com/v1/listen?model=nova-2&language=en-US&smart_format=true&interim_results=true&endpointing=300'
        deepgramSTT = new WebSocket(sttUrl, ['token', deepgramApiKey])

        deepgramSTT.onopen = () => {
          log('‚úÖ DeepGram STT connected successfully')
        }

        deepgramSTT.onmessage = async (event) => {
          try {
            const data = JSON.parse(event.data)
            if (data.type === 'Results' && data.channel?.alternatives?.[0]?.transcript) {
              const transcript = data.channel.alternatives[0].transcript
              const isFinal = data.is_final || false
              
              if (transcript.trim()) {
                log('üìù STT transcript:', { transcript, isFinal })
                
                socket.send(JSON.stringify({
                  type: 'transcript',
                  text: transcript,
                  confidence: data.channel.alternatives[0].confidence || 1.0,
                  isFinal,
                  timestamp: Date.now()
                }))

                if (isFinal) {
                  await processConversation(transcript)
                }
              }
            }
          } catch (error) {
            log('‚ùå Error processing STT message:', error)
          }
        }

        deepgramSTT.onerror = (error) => {
          log('‚ùå DeepGram STT error:', error)
          setTimeout(initializeSTT, 2000) // Reconnect after 2 seconds
        }

        deepgramSTT.onclose = (event) => {
          log('üîå DeepGram STT closed:', event.code)
          if (isCallActive && event.code !== 1000) {
            setTimeout(initializeSTT, 2000) // Reconnect if not normal closure
          }
        }
      } catch (error) {
        log('‚ùå Error initializing STT:', error)
        setTimeout(initializeSTT, 2000)
      }
    }

    // Initialize DeepGram TTS with proper error handling
    const initializeTTS = () => {
      try {
        const ttsUrl = 'wss://api.deepgram.com/v1/speak?model=aura-asteria-en&encoding=linear16&sample_rate=8000'
        deepgramTTS = new WebSocket(ttsUrl, ['token', deepgramApiKey])

        deepgramTTS.onopen = () => {
          log('‚úÖ DeepGram TTS connected successfully')
          // Send initial greeting
          if (assistant.first_message) {
            sendTTSMessage(assistant.first_message)
          }
        }

        deepgramTTS.onmessage = (event) => {
          if (event.data instanceof ArrayBuffer) {
            try {
              // Convert audio to base64 and send to SignalWire
              const audioArray = new Uint8Array(event.data)
              const base64Audio = btoa(String.fromCharCode(...audioArray))
              
              if (signalWireStreamSid && socket.readyState === WebSocket.OPEN) {
                const mediaMessage = {
                  event: 'media',
                  streamSid: signalWireStreamSid,
                  media: {
                    payload: base64Audio
                  }
                }
                socket.send(JSON.stringify(mediaMessage))
                log('üîä Audio sent to SignalWire')
              }
            } catch (error) {
              log('‚ùå Error processing TTS audio:', error)
            }
          }
        }

        deepgramTTS.onerror = (error) => {
          log('‚ùå DeepGram TTS error:', error)
          setTimeout(initializeTTS, 2000)
        }

        deepgramTTS.onclose = (event) => {
          log('üîå DeepGram TTS closed:', event.code)
          if (isCallActive && event.code !== 1000) {
            setTimeout(initializeTTS, 2000)
          }
        }
      } catch (error) {
        log('‚ùå Error initializing TTS:', error)
        setTimeout(initializeTTS, 2000)
      }
    }

    const sendTTSMessage = (text: string) => {
      if (deepgramTTS && deepgramTTS.readyState === WebSocket.OPEN && text.trim()) {
        try {
          const message = {
            type: 'Speak',
            text: text.trim()
          }
          deepgramTTS.send(JSON.stringify(message))
          log('üì§ TTS message sent:', text)
        } catch (error) {
          log('‚ùå Error sending TTS message:', error)
        }
      } else {
        log('‚ö†Ô∏è TTS not ready, queuing message:', text)
        // Queue message for when TTS reconnects
        setTimeout(() => sendTTSMessage(text), 1000)
      }
    }

    const processConversation = async (transcript: string) => {
      try {
        log('üß† Processing conversation:', { input: transcript })
        
        // Add user message to conversation buffer
        conversationBuffer.push({ role: 'user', content: transcript })
        
        // Generate AI response using the conversation service
        const response = await generateConversationResponse(transcript, {
          callId,
          agentPrompt: assistant.system_prompt,
          agentPersonality: assistant.voice_provider === 'friendly' ? 'friendly' : 'professional',
          previousMessages: conversationBuffer
        })
        
        log('ü§ñ AI Response generated:', response)
        
        // Add AI response to conversation buffer
        conversationBuffer.push({ role: 'assistant', content: response.text })
        
        // Send response back to client
        socket.send(JSON.stringify({
          type: 'ai_response',
          text: response.text,
          intent: response.intent,
          confidence: response.confidence,
          shouldTransfer: response.shouldTransfer,
          shouldEndCall: response.shouldEndCall,
          timestamp: Date.now()
        }))

        // Convert response to speech
        sendTTSMessage(response.text)
        
        // Handle call actions
        if (response.shouldEndCall) {
          log('üì¥ Call should end')
          setTimeout(() => {
            socket.send(JSON.stringify({ type: 'end_call', reason: 'ai_decision' }))
          }, 3000) // Give time for TTS to finish
        } else if (response.shouldTransfer) {
          log('üìû Call should transfer')
          socket.send(JSON.stringify({ type: 'transfer_call', reason: 'ai_decision' }))
        }
        
      } catch (error) {
        log('‚ùå Error processing conversation:', error)
        const fallbackResponse = "I'm having trouble processing that. Let me connect you with someone who can help."
        sendTTSMessage(fallbackResponse)
      }
    }

    const cleanup = () => {
      isCallActive = false
      if (deepgramSTT) {
        deepgramSTT.close()
        deepgramSTT = null
      }
      if (deepgramTTS) {
        deepgramTTS.close()
        deepgramTTS = null
      }
      log('üßπ Cleanup completed')
    }

    // WebSocket event handlers
    socket.onopen = () => {
      log('üîå SignalWire WebSocket connected')
      isCallActive = true
      
      // Initialize DeepGram connections
      initializeSTT()
      initializeTTS()
      
      socket.send(JSON.stringify({
        type: 'connection_established',
        callId,
        assistantId,
        assistant: { 
          name: assistant.name,
          personality: assistant.system_prompt,
          first_message: assistant.first_message
        },
        timestamp: Date.now(),
      }))
    }

    socket.onmessage = async (event) => {
      try {
        const msg = JSON.parse(event.data)
        log('üì® Received message:', { event: msg.event || msg.type })
        
        switch (msg.event || msg.type) {
          case 'connected':
            log('üì° SignalWire stream connected')
            break
            
          case 'start':
            signalWireStreamSid = msg.streamSid
            log('üéôÔ∏è SignalWire stream started:', msg.streamSid)
            break
            
          case 'media':
            if (isCallActive && msg.media?.payload && deepgramSTT?.readyState === WebSocket.OPEN) {
              try {
                // Convert base64 audio to binary and send to DeepGram STT
                const binaryAudio = Uint8Array.from(atob(msg.media.payload), c => c.charCodeAt(0))
                deepgramSTT.send(binaryAudio)
              } catch (error) {
                log('‚ùå Error processing media:', error)
              }
            }
            break
            
          case 'stop':
            log('üõë SignalWire stream stopped')
            isCallActive = false
            signalWireStreamSid = null
            cleanup()
            break
            
          case 'text_input':
            if (msg.text?.trim()) {
              await processConversation(msg.text)
            }
            break
            
          default:
            log('‚ùì Unknown SignalWire event:', msg)
        }
      } catch (err) {
        log('‚ùå Error processing SignalWire message:', err)
      }
    }

    socket.onclose = (ev) => {
      log('üîå SignalWire WebSocket closed:', ev.code)
      cleanup()
    }

    socket.onerror = (err) => {
      log('‚ùå SignalWire WebSocket error:', err)
      cleanup()
    }

    return response
  } catch (error) {
    console.error('‚ùå Critical error:', error)
    return new Response(
      JSON.stringify({ error: 'Internal server error', details: error.message }),
      { status: 500, headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
    )
  }
})
